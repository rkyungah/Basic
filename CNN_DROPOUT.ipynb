{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "191004_CNN_DROPOUT.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7VjGS4VVxWX",
        "colab_type": "text"
      },
      "source": [
        "### **Dropout**\n",
        "\n",
        "* 과적합의 이해 - 학습 결과가 학습 데이터에는 매우 잘 맞지만, 학습 데이터에만 꼭 맞춰져 그 외의 데이터에는 잘 안 맞는다.\n",
        "* 학습시 전체 신경망 중 **일부**만을 사용하도록 하는 것.\n",
        "* 즉 학습 단계마다 일부 뉴런을 제거(사용X)함으로써 일부 특징이 특정 뉴런에 고정되는 것을 막아 가중치의 균형을 잡도록 한다.\n",
        "* 학습시 일부 뉴런을 학습시키지 않기 때문에 신경망이 **충분히 학습되기까지**의 시간은 조금 더 **오래** 걸리는 편이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTPyfbTdWSLE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, warnings\n",
        "# 경고 메시지 무시하거나 숨길때(ignore), 다시보이게(default)\n",
        "# warnings.filterwarnings(action='default')\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGEhPKIAWT4w",
        "colab_type": "code",
        "outputId": "104488b2-4def-4d84-cd51-89c335b585ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets('./mnist/data', one_hot=True)\n",
        "type(mnist)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.contrib.learn.python.learn.datasets.base.Datasets"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzHaP5LaWgaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 신경망 모델 구성하기\n",
        "## 1. 문제와 답\n",
        "X = tf.placeholder(tf.float32, [None, 784])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oGhIOu-oXAB0",
        "colab_type": "text"
      },
      "source": [
        "## **미니배치의 이해**\n",
        "\n",
        "* 이미지를 하나하나 학습시키는 것보다 여러 개를 한꺼번에 학습시키는 쪽이 효과가 좋다.\n",
        "* 많은 메모리와 높은 컴퓨터 성능이 필요하므로 일반적으로 데이터를 적당한 크기로 잘라 학습시킨다.\n",
        "  * 미니배치라고 한다.\n",
        "* tf.float32, [None, 784] => None의 자리에는 한번에 학습시킬 이미지의 개수를 지정하는 값이 들어감. 즉, 배치 크기를 지정하는 자리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-J12YlrLW-6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 미니 배치\n",
        "batch_size = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3r517ip5XdDO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## 신경망\n",
        "# 입력층 784\n",
        "# 첫번째 256\n",
        "# 두번째 256\n",
        "# 출력층 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGQXXp8GXuKZ",
        "colab_type": "text"
      },
      "source": [
        "### tf.nn.dropout(Layer, 비율)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA5APFwaX2J3",
        "colab_type": "code",
        "outputId": "bdfca04e-81f8-4561-a59a-1ea583e42870",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
        "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
        "L1 = tf.nn.dropout(L1, keep_prob)\n",
        "\n",
        "W2 = tf.Variable(tf.random_normal([256,256],stddev=0.01))\n",
        "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
        "L2 = tf.nn.dropout(L2, keep_prob)  # 뒤의 뉴런을 0.8만 이용\n",
        "\n",
        "W3 = tf.Variable(tf.random_normal([256,10],stddev=0.01))\n",
        "model = tf.matmul(L2, W3)\n",
        "\n",
        "print(W3)\n",
        "print(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-7-cf99d4f897af>:5: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "<tf.Variable 'Variable_2:0' shape=(256, 10) dtype=float32_ref>\n",
            "Tensor(\"MatMul_2:0\", shape=(?, 10), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6zQZu7rYZ7C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 비용함수, 최적화함수\n",
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model,\n",
        "                                                        labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaFqkWzCY8L_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 세션 초기화 훈련\n",
        "sess= tf.Session()\n",
        "sess.run(tf.global_variables_initializer())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hasfbfVTZZl1",
        "colab_type": "text"
      },
      "source": [
        "### **배치 사이즈 지정**\n",
        "\n",
        "* Mini-batch 크기가 전체 트레이닝 셋 데이터 사이즈인 m과 같다면 이것은 Batch gradient descent\n",
        "   * 데이터가 별로 없다면 batch gradient descent 사용\n",
        "* Mini-batch 크기가 1이라면 Stochastic gradient descent\n",
        "   * **적은 메모리**로 동작 가능\n",
        "   * 64, 128, 256, 512 사이즈 선택"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KLotIrRZSSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAxBKH5maUBv",
        "colab_type": "code",
        "outputId": "e3e0cb6a-d6c1-491d-c7ab-512790ad85a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        }
      },
      "source": [
        "# 데이터 전체 학습 15회\n",
        "\n",
        "for epoch in range(15) :\n",
        "  total_cost = 0\n",
        "\n",
        "  for i in range(total_batch) :\n",
        "    batch_image, batch_label = mnist.train.next_batch(batch_size)\n",
        "\n",
        "    _, cost_val = sess.run([optimizer, cost],\n",
        "                          feed_dict={X: batch_image,\n",
        "                                    Y: batch_label,\n",
        "                                    keep_prob : 0.8})\n",
        "\n",
        "    # 총 손실\n",
        "    total_cost = total_cost + cost_val\n",
        "\n",
        "  print(\"Epoch : %4d\" % (epoch +1),\n",
        "        \"평균 cost :\",\"{:.3f}\".format(total_cost / total_batch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch :    1 평균 cost : 0.429\n",
            "Epoch :    2 평균 cost : 0.169\n",
            "Epoch :    3 평균 cost : 0.112\n",
            "Epoch :    4 평균 cost : 0.088\n",
            "Epoch :    5 평균 cost : 0.070\n",
            "Epoch :    6 평균 cost : 0.061\n",
            "Epoch :    7 평균 cost : 0.054\n",
            "Epoch :    8 평균 cost : 0.048\n",
            "Epoch :    9 평균 cost : 0.040\n",
            "Epoch :   10 평균 cost : 0.037\n",
            "Epoch :   11 평균 cost : 0.033\n",
            "Epoch :   12 평균 cost : 0.029\n",
            "Epoch :   13 평균 cost : 0.030\n",
            "Epoch :   14 평균 cost : 0.027\n",
            "Epoch :   15 평균 cost : 0.027\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}