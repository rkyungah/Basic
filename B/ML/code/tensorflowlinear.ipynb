{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.5) \n",
    "# GradientDescentOptimizer 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sect3. Cost 최소화기법, How to minimize cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex01. Multi-variable linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_5:0\", dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "x1_data = [73., 93., 89., 96., 73.]\n",
    "x2_data = [80., 88., 91., 98., 66.]\n",
    "x3_data = [75., 93., 90., 100., 70.]\n",
    "\n",
    "y_data = [152., 185., 180., 196., 142.]\n",
    "\n",
    "x1 = tf.placeholder(tf.float32)\n",
    "x2 = tf.placeholder(tf.float32)\n",
    "x3 = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "w1 = tf.Variable(tf.random_normal([1]), name='weight1')\n",
    "w2 = tf.Variable(tf.random_normal([1]), name='weight2')\n",
    "w3 = tf.Variable(tf.random_normal([1]), name='weight3')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = x1*w1 + x2*w2 + x3*w3 + b\n",
    "print(hypothesis)\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "813760914d554144b2d9c0afb7b8bfcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 27199.822265625 \n",
      "Prediction :\n",
      "[-4.746768  15.750464   4.27555    5.7535353 16.655096 ]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 8558.369140625 \n",
      "Prediction :\n",
      "[59.607788 93.09478  80.48686  88.745415 75.64831 ]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 2715.2490234375 \n",
      "Prediction :\n",
      "[ 95.63871 136.3962  123.15513 135.20978 108.67539]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 883.7234497070312 \n",
      "Prediction :\n",
      "[115.81229 160.63828 147.04388 161.22372 127.16497]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 309.62017822265625 \n",
      "Prediction :\n",
      "[127.1079  174.2097  160.41869 175.78822 137.51556]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 129.65162658691406 \n",
      "Prediction :\n",
      "[133.43309 181.80704 167.9071  183.94263 143.30942]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 73.22370910644531 \n",
      "Prediction :\n",
      "[136.9755  186.0597  172.09995 188.5082  146.55212]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 55.51879119873047 \n",
      "Prediction :\n",
      "[138.95995 188.43977 174.44772 191.06458 148.36653]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 49.951637268066406 \n",
      "Prediction :\n",
      "[140.07216 189.77151 175.76254 192.49606 149.38132]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 48.18914031982422 \n",
      "Prediction :\n",
      "[140.69601 190.5163  176.49901 193.29774 149.9484 ]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 45.12461471557617 \n",
      "Prediction :\n",
      "[141.72708 191.30096 177.50871 194.36923 150.45708]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 42.75444412231445 \n",
      "Prediction :\n",
      "[141.98502 191.1242  177.58788 194.42535 150.22609]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 40.509361267089844 \n",
      "Prediction :\n",
      "[142.23611 190.95224 177.66498 194.48001 150.00134]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 38.38257598876953 \n",
      "Prediction :\n",
      "[142.48048 190.7848  177.74    194.53316 149.78258]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 36.36799240112305 \n",
      "Prediction :\n",
      "[142.71834 190.62184 177.81303 194.58485 149.56969]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 34.45978546142578 \n",
      "Prediction :\n",
      "[142.94984 190.46327 177.88411 194.63515 149.3625 ]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 32.65210723876953 \n",
      "Prediction :\n",
      "[143.1752  190.30888 177.9533  194.68407 149.1609 ]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 30.939807891845703 \n",
      "Prediction :\n",
      "[143.39453 190.15863 178.02063 194.73167 148.96469]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 29.317895889282227 \n",
      "Prediction :\n",
      "[143.60799 190.0124  178.0862  194.77797 148.77373]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 27.781513214111328 \n",
      "Prediction :\n",
      "[143.81577 189.87009 178.15    194.82301 148.58789]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 26.326147079467773 \n",
      "Prediction :\n",
      "[144.01802 189.73157 178.2121  194.86685 148.40706]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 24.947603225708008 \n",
      "Prediction :\n",
      "[144.21484 189.59674 178.27255 194.90945 148.23105]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 23.64158058166504 \n",
      "Prediction :\n",
      "[144.40646 189.46548 178.3314  194.95093 148.05977]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 22.40459632873535 \n",
      "Prediction :\n",
      "[144.59294 189.33775 178.38869 194.99123 147.89308]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 21.232831954956055 \n",
      "Prediction :\n",
      "[144.77444 189.21342 178.44444 195.03047 147.73087]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 20.122867584228516 \n",
      "Prediction :\n",
      "[144.95113 189.09242 178.49872 195.06862 147.57301]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 19.071537017822266 \n",
      "Prediction :\n",
      "[145.12308 188.97467 178.55156 195.10574 147.4194 ]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 18.075523376464844 \n",
      "Prediction :\n",
      "[145.29047 188.86003 178.60298 195.14183 147.2699 ]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 17.132110595703125 \n",
      "Prediction :\n",
      "[145.45338 188.74846 178.65303 195.17694 147.12442]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 16.23847007751465 \n",
      "Prediction :\n",
      "[145.61194 188.63986 178.70177 195.21109 146.98283]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "# Initializes global variables in the graph.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "    cost_val, hy_val, _ = sess.run([cost, hypothesis, train],\n",
    "                                   feed_dict={x1: x1_data, x2: x2_data, x3: x3_data, Y: y_data})\n",
    "\n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex02. Multi-variable matmul linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "x_data = [[73., 80., 75.], \n",
    "          [93., 88., 93.],\n",
    "          [89., 91., 90.], \n",
    "          [96., 98., 100.], \n",
    "          [73., 66., 70.]]\n",
    "y_data = [[152.], [185.], [180.], [196.], [142.]]\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape = [None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate =1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bcf49df75a43df9a67754bc6bebc55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 14491.9814453125 \n",
      " Prediction : \n",
      "[[43.877033]\n",
      " [56.758087]\n",
      " [53.818756]\n",
      " [58.703094]\n",
      " [44.26979 ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 4542.75244140625 \n",
      " Prediction : \n",
      "[[ 90.890015]\n",
      " [113.26388 ]\n",
      " [109.49504 ]\n",
      " [119.33313 ]\n",
      " [ 87.36943 ]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 1424.196533203125 \n",
      " Prediction : \n",
      "[[117.21093]\n",
      " [144.89935]\n",
      " [140.66617]\n",
      " [153.27768]\n",
      " [111.49928]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 446.69488525390625 \n",
      " Prediction : \n",
      "[[131.94711]\n",
      " [162.61084]\n",
      " [158.11777]\n",
      " [172.282  ]\n",
      " [125.00865]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 140.30014038085938 \n",
      " Prediction : \n",
      "[[140.19743]\n",
      " [172.52681]\n",
      " [167.88829]\n",
      " [182.92183]\n",
      " [132.57198]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 44.2617073059082 \n",
      " Prediction : \n",
      "[[144.81656]\n",
      " [178.07834]\n",
      " [173.35847]\n",
      " [188.87866]\n",
      " [136.80635]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 14.158638000488281 \n",
      " Prediction : \n",
      "[[147.4027 ]\n",
      " [181.1864 ]\n",
      " [176.42105]\n",
      " [192.2137 ]\n",
      " [139.17697]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 4.7228569984436035 \n",
      " Prediction : \n",
      "[[148.85066]\n",
      " [182.92644]\n",
      " [178.1357 ]\n",
      " [194.08087]\n",
      " [140.50414]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 1.7651798725128174 \n",
      " Prediction : \n",
      "[[149.66139]\n",
      " [183.90057]\n",
      " [179.09569]\n",
      " [195.12625]\n",
      " [141.2471 ]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 0.8380519151687622 \n",
      " Prediction : \n",
      "[[150.11536]\n",
      " [184.44589]\n",
      " [179.63318]\n",
      " [195.71152]\n",
      " [141.66301]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 0.40681833028793335 \n",
      " Prediction : \n",
      "[[150.7071 ]\n",
      " [185.12993]\n",
      " [180.32143]\n",
      " [196.45796]\n",
      " [142.18054]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 0.3984677195549011 \n",
      " Prediction : \n",
      "[[150.72263]\n",
      " [185.11943]\n",
      " [180.32635]\n",
      " [196.46005]\n",
      " [142.16803]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 0.3905394673347473 \n",
      " Prediction : \n",
      "[[150.73773]\n",
      " [185.1092 ]\n",
      " [180.33118]\n",
      " [196.46204]\n",
      " [142.15587]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 0.3830018937587738 \n",
      " Prediction : \n",
      "[[150.75247]\n",
      " [185.09927]\n",
      " [180.33588]\n",
      " [196.46396]\n",
      " [142.14407]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 0.37583914399147034 \n",
      " Prediction : \n",
      "[[150.76683]\n",
      " [185.08957]\n",
      " [180.34047]\n",
      " [196.46579]\n",
      " [142.13261]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 0.3690322935581207 \n",
      " Prediction : \n",
      "[[150.78082]\n",
      " [185.08012]\n",
      " [180.34496]\n",
      " [196.46754]\n",
      " [142.12148]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 0.3625571131706238 \n",
      " Prediction : \n",
      "[[150.79448]\n",
      " [185.07095]\n",
      " [180.34932]\n",
      " [196.46925]\n",
      " [142.11067]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 0.35641202330589294 \n",
      " Prediction : \n",
      "[[150.80774]\n",
      " [185.06198]\n",
      " [180.35358]\n",
      " [196.47084]\n",
      " [142.10013]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 0.35056233406066895 \n",
      " Prediction : \n",
      "[[150.8207 ]\n",
      " [185.05325]\n",
      " [180.35773]\n",
      " [196.4724 ]\n",
      " [142.08992]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 0.34499743580818176 \n",
      " Prediction : \n",
      "[[150.83331]\n",
      " [185.04475]\n",
      " [180.36177]\n",
      " [196.47386]\n",
      " [142.08002]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 0.33970776200294495 \n",
      " Prediction : \n",
      "[[150.84561]\n",
      " [185.03647]\n",
      " [180.36574]\n",
      " [196.47527]\n",
      " [142.07039]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 0.33467310667037964 \n",
      " Prediction : \n",
      "[[150.85759]\n",
      " [185.0284 ]\n",
      " [180.36958]\n",
      " [196.4766 ]\n",
      " [142.06104]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 0.3298836350440979 \n",
      " Prediction : \n",
      "[[150.86926]\n",
      " [185.02054]\n",
      " [180.37334]\n",
      " [196.47786]\n",
      " [142.05196]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 0.3253173232078552 \n",
      " Prediction : \n",
      "[[150.88066]\n",
      " [185.0129 ]\n",
      " [180.37703]\n",
      " [196.47905]\n",
      " [142.04314]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 0.32098454236984253 \n",
      " Prediction : \n",
      "[[150.89174]\n",
      " [185.00542]\n",
      " [180.3806 ]\n",
      " [196.48021]\n",
      " [142.03455]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 0.31685104966163635 \n",
      " Prediction : \n",
      "[[150.90256]\n",
      " [184.99815]\n",
      " [180.38411]\n",
      " [196.4813 ]\n",
      " [142.02625]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 0.3129104971885681 \n",
      " Prediction : \n",
      "[[150.9131 ]\n",
      " [184.99107]\n",
      " [180.38751]\n",
      " [196.48232]\n",
      " [142.01817]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 0.30915629863739014 \n",
      " Prediction : \n",
      "[[150.92339]\n",
      " [184.98418]\n",
      " [180.39084]\n",
      " [196.48329]\n",
      " [142.01035]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 0.30559012293815613 \n",
      " Prediction : \n",
      "[[150.9334 ]\n",
      " [184.97745]\n",
      " [180.3941 ]\n",
      " [196.48422]\n",
      " [142.00272]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 0.30218052864074707 \n",
      " Prediction : \n",
      "[[150.94318]\n",
      " [184.97092]\n",
      " [180.39728]\n",
      " [196.4851 ]\n",
      " [141.99536]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess= tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)) :\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "    [cost, hypothesis, train], feed_dict = {X: x_data, Y : y_data})\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\n Prediction : \\n{}\".format(\n",
    "        step,cost_val,hy_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex03. File input linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "xy = np.loadtxt('./data/data-01-test-score.csv', delimiter = ',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_data.shape : (25, 3), \tlen(x_data) : 25 \n",
      "x_data : \n",
      "[[ 73.  80.  75.]\n",
      " [ 93.  88.  93.]\n",
      " [ 89.  91.  90.]\n",
      " [ 96.  98. 100.]\n",
      " [ 73.  66.  70.]\n",
      " [ 53.  46.  55.]\n",
      " [ 69.  74.  77.]\n",
      " [ 47.  56.  60.]\n",
      " [ 87.  79.  90.]\n",
      " [ 79.  70.  88.]\n",
      " [ 69.  70.  73.]\n",
      " [ 70.  65.  74.]\n",
      " [ 93.  95.  91.]\n",
      " [ 79.  80.  73.]\n",
      " [ 70.  73.  78.]\n",
      " [ 93.  89.  96.]\n",
      " [ 78.  75.  68.]\n",
      " [ 81.  90.  93.]\n",
      " [ 88.  92.  86.]\n",
      " [ 78.  83.  77.]\n",
      " [ 82.  86.  90.]\n",
      " [ 86.  82.  89.]\n",
      " [ 78.  83.  85.]\n",
      " [ 76.  83.  71.]\n",
      " [ 96.  93.  95.]]\n",
      "-------------------------\n",
      "y_data.shape : (25, 1)  \n",
      "y_data : \n",
      "[[152.]\n",
      " [185.]\n",
      " [180.]\n",
      " [196.]\n",
      " [142.]\n",
      " [101.]\n",
      " [149.]\n",
      " [115.]\n",
      " [175.]\n",
      " [164.]\n",
      " [141.]\n",
      " [141.]\n",
      " [184.]\n",
      " [152.]\n",
      " [148.]\n",
      " [192.]\n",
      " [147.]\n",
      " [183.]\n",
      " [177.]\n",
      " [159.]\n",
      " [177.]\n",
      " [175.]\n",
      " [175.]\n",
      " [149.]\n",
      " [192.]]\n"
     ]
    }
   ],
   "source": [
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]\n",
    "\n",
    "print(\"x_data.shape : {}, \\tlen(x_data) : {} \\nx_data : \\n{}\".format(x_data.shape, len(x_data), x_data))\n",
    "print(\"-\"*25)\n",
    "print(\"y_data.shape : {}  \\ny_data : \\n{}\".format(y_data.shape, y_data))\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3, 1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X,W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step : 0 \n",
      "Cost : 30871.0390625 \n",
      "Prediction :\n",
      "[[-20.513838  ]\n",
      " [ -6.5941644 ]\n",
      " [-15.889416  ]\n",
      " [-15.902521  ]\n",
      " [ -1.764229  ]\n",
      " [  2.8374803 ]\n",
      " [-14.993187  ]\n",
      " [-15.9369335 ]\n",
      " [ -0.33107403]\n",
      " [  4.3142447 ]\n",
      " [-10.500959  ]\n",
      " [ -1.8907492 ]\n",
      " [-17.482384  ]\n",
      " [-15.324179  ]\n",
      " [-12.220448  ]\n",
      " [ -7.0446    ]\n",
      " [-10.685949  ]\n",
      " [-21.23749   ]\n",
      " [-19.671099  ]\n",
      " [-19.334084  ]\n",
      " [-15.431911  ]\n",
      " [ -6.0225434 ]\n",
      " [-16.643566  ]\n",
      " [-23.306065  ]\n",
      " [-10.287249  ]]\n",
      "\n",
      "Step : 1 \n",
      "Cost : 11448.2578125 \n",
      "Prediction :\n",
      "[[44.18243 ]\n",
      " [71.159454]\n",
      " [60.72527 ]\n",
      " [67.53627 ]\n",
      " [57.53459 ]\n",
      " [46.55481 ]\n",
      " [47.46454 ]\n",
      " [30.366795]\n",
      " [72.33347 ]\n",
      " [71.61786 ]\n",
      " [49.672665]\n",
      " [57.439198]\n",
      " [61.67152 ]\n",
      " [50.47614 ]\n",
      " [50.523514]\n",
      " [71.85713 ]\n",
      " [51.979065]\n",
      " [53.718845]\n",
      " [55.791725]\n",
      " [48.18766 ]\n",
      " [57.80907 ]\n",
      " [66.9207  ]\n",
      " [53.18651 ]\n",
      " [41.924053]\n",
      " [70.29643 ]]\n",
      "\n",
      "Step : 2 \n",
      "Cost : 4267.099609375 \n",
      "Prediction :\n",
      "[[ 83.52226 ]\n",
      " [118.43691 ]\n",
      " [107.31133 ]\n",
      " [118.27162 ]\n",
      " [ 93.59035 ]\n",
      " [ 73.136   ]\n",
      " [ 85.44264 ]\n",
      " [ 58.52291 ]\n",
      " [116.515884]\n",
      " [112.54017 ]\n",
      " [ 86.261406]\n",
      " [ 93.51395 ]\n",
      " [109.80167 ]\n",
      " [ 90.48658 ]\n",
      " [ 88.67535 ]\n",
      " [119.832756]\n",
      " [ 90.082565]\n",
      " [ 99.29728 ]\n",
      " [101.677826]\n",
      " [ 89.2453  ]\n",
      " [102.343796]\n",
      " [111.27326 ]\n",
      " [ 95.64743 ]\n",
      " [ 81.588745]\n",
      " [119.295074]]\n",
      "\n",
      "Step : 3 \n",
      "Cost : 1612.0084228515625 \n",
      "Prediction :\n",
      "[[107.44403 ]\n",
      " [147.18326 ]\n",
      " [135.63838 ]\n",
      " [149.12157 ]\n",
      " [115.5131  ]\n",
      " [ 89.29754 ]\n",
      " [108.53587 ]\n",
      " [ 75.64431 ]\n",
      " [143.37967 ]\n",
      " [137.42125 ]\n",
      " [108.509315]\n",
      " [115.448326]\n",
      " [139.06773 ]\n",
      " [114.81543 ]\n",
      " [111.87386 ]\n",
      " [149.00368 ]\n",
      " [113.25138 ]\n",
      " [127.01242 ]\n",
      " [129.57973 ]\n",
      " [114.21137 ]\n",
      " [129.4236  ]\n",
      " [138.24118 ]\n",
      " [121.46648 ]\n",
      " [105.70832 ]\n",
      " [149.08838 ]]\n",
      "\n",
      "Step : 4 \n",
      "Cost : 630.3294677734375 \n",
      "Prediction :\n",
      "[[121.99082 ]\n",
      " [164.66173 ]\n",
      " [152.86304 ]\n",
      " [167.88013 ]\n",
      " [128.84222 ]\n",
      " [ 99.123375]\n",
      " [122.5783  ]\n",
      " [ 86.05602 ]\n",
      " [159.71284 ]\n",
      " [152.54843 ]\n",
      " [122.037224]\n",
      " [128.78459 ]\n",
      " [156.86345 ]\n",
      " [129.60904 ]\n",
      " [125.97999 ]\n",
      " [166.74036 ]\n",
      " [127.33912 ]\n",
      " [143.86572 ]\n",
      " [146.5463  ]\n",
      " [129.39291 ]\n",
      " [145.88992 ]\n",
      " [154.6383  ]\n",
      " [137.16638 ]\n",
      " [120.37563 ]\n",
      " [167.2038  ]]\n",
      "\n",
      "Step : 5 \n",
      "Cost : 267.35614013671875 \n",
      "Prediction :\n",
      "[[130.83714]\n",
      " [175.28877]\n",
      " [163.33687]\n",
      " [179.28656]\n",
      " [136.94604]\n",
      " [105.09677]\n",
      " [131.11739]\n",
      " [ 92.38792]\n",
      " [169.64285]\n",
      " [161.74478]\n",
      " [130.26295]\n",
      " [136.89279]\n",
      " [167.68462]\n",
      " [138.60475]\n",
      " [134.55748]\n",
      " [177.52446]\n",
      " [135.9051 ]\n",
      " [154.1145 ]\n",
      " [156.86363]\n",
      " [138.625  ]\n",
      " [155.90273]\n",
      " [164.60791]\n",
      " [146.71335]\n",
      " [129.2955 ]\n",
      " [178.21852]]\n",
      "\n",
      "Step : 6 \n",
      "Cost : 133.13693237304688 \n",
      "Prediction :\n",
      "[[136.21724 ]\n",
      " [181.74973 ]\n",
      " [169.70578 ]\n",
      " [186.22244 ]\n",
      " [141.87251 ]\n",
      " [108.727684]\n",
      " [136.31012 ]\n",
      " [ 96.23905 ]\n",
      " [175.67938 ]\n",
      " [167.33478 ]\n",
      " [135.26463 ]\n",
      " [141.82202 ]\n",
      " [174.26486 ]\n",
      " [144.07501 ]\n",
      " [139.77322 ]\n",
      " [184.08098 ]\n",
      " [141.11354 ]\n",
      " [160.34732 ]\n",
      " [163.13783 ]\n",
      " [144.23944 ]\n",
      " [161.99138 ]\n",
      " [170.66914 ]\n",
      " [152.51897 ]\n",
      " [134.72058 ]\n",
      " [184.91559 ]]\n",
      "\n",
      "Step : 7 \n",
      "Cost : 83.49371337890625 \n",
      "Prediction :\n",
      "[[139.48973]\n",
      " [185.67752]\n",
      " [173.57874]\n",
      " [190.44   ]\n",
      " [144.86703]\n",
      " [110.93424]\n",
      " [139.46812]\n",
      " [ 98.58176]\n",
      " [179.34851]\n",
      " [170.73203]\n",
      " [138.30595]\n",
      " [144.8183 ]\n",
      " [178.26642]\n",
      " [147.40161]\n",
      " [142.9449 ]\n",
      " [188.06693]\n",
      " [144.28046]\n",
      " [164.13826]\n",
      " [166.95364]\n",
      " [147.6542 ]\n",
      " [165.69397]\n",
      " [174.35394]\n",
      " [156.04968]\n",
      " [138.0207 ]\n",
      " [188.9873 ]]\n",
      "\n",
      "Step : 8 \n",
      "Cost : 65.12068939208984 \n",
      "Prediction :\n",
      "[[141.48067]\n",
      " [188.06502]\n",
      " [175.934  ]\n",
      " [193.00471]\n",
      " [146.68684]\n",
      " [112.27471]\n",
      " [141.38889]\n",
      " [100.00725]\n",
      " [181.57808]\n",
      " [172.79587]\n",
      " [140.15526]\n",
      " [146.6392 ]\n",
      " [180.7    ]\n",
      " [149.42476]\n",
      " [144.87364]\n",
      " [190.48985]\n",
      " [146.20598]\n",
      " [166.44441]\n",
      " [169.27461]\n",
      " [149.73143]\n",
      " [167.94574]\n",
      " [176.59373]\n",
      " [158.1971 ]\n",
      " [140.0287 ]\n",
      " [191.46268]]\n",
      "\n",
      "Step : 9 \n",
      "Cost : 58.30916976928711 \n",
      "Prediction :\n",
      "[[142.69237 ]\n",
      " [189.51591 ]\n",
      " [177.36644 ]\n",
      " [194.56439 ]\n",
      " [147.79234 ]\n",
      " [113.08858 ]\n",
      " [142.55736 ]\n",
      " [100.875046]\n",
      " [182.93237 ]\n",
      " [174.04903 ]\n",
      " [141.27975 ]\n",
      " [147.74547 ]\n",
      " [182.18016 ]\n",
      " [150.65535 ]\n",
      " [146.04663 ]\n",
      " [191.96233 ]\n",
      " [147.3767  ]\n",
      " [167.84773 ]\n",
      " [170.68663 ]\n",
      " [150.99538 ]\n",
      " [169.31529 ]\n",
      " [177.95488 ]\n",
      " [159.50343 ]\n",
      " [141.251   ]\n",
      " [192.96739 ]]\n",
      "\n",
      "Step : 100 \n",
      "Cost : 51.731849670410156 \n",
      "Prediction :\n",
      "[[144.8182 ]\n",
      " [191.5841 ]\n",
      " [179.65768]\n",
      " [197.02872]\n",
      " [149.27426]\n",
      " [114.07639]\n",
      " [144.49251]\n",
      " [102.45059]\n",
      " [184.71442]\n",
      " [175.5875 ]\n",
      " [143.03088]\n",
      " [149.24539]\n",
      " [184.57022]\n",
      " [152.65337]\n",
      " [147.91452]\n",
      " [194.07657]\n",
      " [149.16595]\n",
      " [170.26343]\n",
      " [173.04509]\n",
      " [153.15274]\n",
      " [171.5257 ]\n",
      " [179.89615]\n",
      " [161.66095]\n",
      " [143.45084]\n",
      " [195.20166]]\n",
      "\n",
      "Step : 200 \n",
      "Cost : 49.04936981201172 \n",
      "Prediction :\n",
      "[[145.08403]\n",
      " [191.3858 ]\n",
      " [179.73175]\n",
      " [197.07741]\n",
      " [149.02066]\n",
      " [113.77967]\n",
      " [144.62685]\n",
      " [102.70233]\n",
      " [184.36995]\n",
      " [175.15158]\n",
      " [143.03871]\n",
      " [149.01239]\n",
      " [184.66992]\n",
      " [152.74663]\n",
      " [147.9686 ]\n",
      " [193.89285]\n",
      " [149.13269]\n",
      " [170.52463]\n",
      " [173.22496]\n",
      " [153.36397]\n",
      " [171.62027]\n",
      " [179.71225]\n",
      " [161.80406]\n",
      " [143.77637]\n",
      " [195.09225]]\n",
      "\n",
      "Step : 300 \n",
      "Cost : 46.53648376464844 \n",
      "Prediction :\n",
      "[[145.34044]\n",
      " [191.19354]\n",
      " [179.80266]\n",
      " [197.12482]\n",
      " [148.77423]\n",
      " [113.4936 ]\n",
      " [144.75856]\n",
      " [102.94928]\n",
      " [184.03783]\n",
      " [174.73341]\n",
      " [143.04697]\n",
      " [148.7883 ]\n",
      " [184.7645 ]\n",
      " [152.83368]\n",
      " [148.02289]\n",
      " [193.71573]\n",
      " [149.09628]\n",
      " [170.77997]\n",
      " [173.39688]\n",
      " [153.56659]\n",
      " [171.71344]\n",
      " [179.53499]\n",
      " [161.94377]\n",
      " [144.08786]\n",
      " [194.98535]]\n",
      "\n",
      "Step : 400 \n",
      "Cost : 44.1815299987793 \n",
      "Prediction :\n",
      "[[145.58778 ]\n",
      " [191.00716 ]\n",
      " [179.87053 ]\n",
      " [197.171   ]\n",
      " [148.53474 ]\n",
      " [113.21774 ]\n",
      " [144.88766 ]\n",
      " [103.191475]\n",
      " [183.71758 ]\n",
      " [174.33226 ]\n",
      " [143.05562 ]\n",
      " [148.57277 ]\n",
      " [184.85413 ]\n",
      " [152.91487 ]\n",
      " [148.07727 ]\n",
      " [193.54495 ]\n",
      " [149.05699 ]\n",
      " [171.02962 ]\n",
      " [173.56123 ]\n",
      " [153.76099 ]\n",
      " [171.80528 ]\n",
      " [179.36418 ]\n",
      " [162.08018 ]\n",
      " [144.38597 ]\n",
      " [194.88095 ]]\n",
      "\n",
      "Step : 500 \n",
      "Cost : 41.97384262084961 \n",
      "Prediction :\n",
      "[[145.8264  ]\n",
      " [190.8264  ]\n",
      " [179.93549 ]\n",
      " [197.21593 ]\n",
      " [148.30196 ]\n",
      " [112.95174 ]\n",
      " [145.0142  ]\n",
      " [103.428986]\n",
      " [183.4087  ]\n",
      " [173.94737 ]\n",
      " [143.06462 ]\n",
      " [148.36548 ]\n",
      " [184.93906 ]\n",
      " [152.99046 ]\n",
      " [148.1317  ]\n",
      " [193.38026 ]\n",
      " [149.01506 ]\n",
      " [171.27364 ]\n",
      " [173.71828 ]\n",
      " [153.94746 ]\n",
      " [171.8957  ]\n",
      " [179.19952 ]\n",
      " [162.21336 ]\n",
      " [144.67122 ]\n",
      " [194.77895 ]]\n",
      "\n",
      "Step : 600 \n",
      "Cost : 39.903438568115234 \n",
      "Prediction :\n",
      "[[146.05663]\n",
      " [190.65112]\n",
      " [179.99767]\n",
      " [197.25969]\n",
      " [148.07571]\n",
      " [112.69518]\n",
      " [145.13823]\n",
      " [103.66187]\n",
      " [183.1108 ]\n",
      " [173.57814]\n",
      " [143.07393]\n",
      " [148.16605]\n",
      " [185.01952]\n",
      " [153.06079]\n",
      " [148.18614]\n",
      " [193.22145]\n",
      " [148.97069]\n",
      " [171.51219]\n",
      " [173.8684 ]\n",
      " [154.12639]\n",
      " [171.98476]\n",
      " [179.04079]\n",
      " [162.34337]\n",
      " [144.94417]\n",
      " [194.67932]]\n",
      "\n",
      "Step : 700 \n",
      "Cost : 37.961181640625 \n",
      "Prediction :\n",
      "[[146.27878 ]\n",
      " [190.4812  ]\n",
      " [180.05722 ]\n",
      " [197.3023  ]\n",
      " [147.85583 ]\n",
      " [112.447754]\n",
      " [145.25977 ]\n",
      " [103.8902  ]\n",
      " [182.82349 ]\n",
      " [173.22386 ]\n",
      " [143.08356 ]\n",
      " [147.97421 ]\n",
      " [185.09578 ]\n",
      " [153.12613 ]\n",
      " [148.24051 ]\n",
      " [193.0683  ]\n",
      " [148.92415 ]\n",
      " [171.74539 ]\n",
      " [174.0119  ]\n",
      " [154.29808 ]\n",
      " [172.07245 ]\n",
      " [178.88779 ]\n",
      " [162.4703  ]\n",
      " [145.20544 ]\n",
      " [194.58206 ]]\n",
      "\n",
      "Step : 800 \n",
      "Cost : 36.13839340209961 \n",
      "Prediction :\n",
      "[[146.49315]\n",
      " [190.31635]\n",
      " [180.11421]\n",
      " [197.34378]\n",
      " [147.64207]\n",
      " [112.20907]\n",
      " [145.37883]\n",
      " [104.11401]\n",
      " [182.54631]\n",
      " [172.8839 ]\n",
      " [143.09343]\n",
      " [147.78966]\n",
      " [185.16795]\n",
      " [153.18672]\n",
      " [148.29475]\n",
      " [192.92056]\n",
      " [148.87556]\n",
      " [171.97333]\n",
      " [174.149  ]\n",
      " [154.46281]\n",
      " [172.15875]\n",
      " [178.74025]\n",
      " [162.59422]\n",
      " [145.45543]\n",
      " [194.48703]]\n",
      "\n",
      "Step : 900 \n",
      "Cost : 34.42721939086914 \n",
      "Prediction :\n",
      "[[146.70003]\n",
      " [190.15645]\n",
      " [180.16876]\n",
      " [197.38417]\n",
      " [147.43427]\n",
      " [111.97882]\n",
      " [145.49547]\n",
      " [104.33339]\n",
      " [182.2789 ]\n",
      " [172.55768]\n",
      " [143.10352]\n",
      " [147.61205]\n",
      " [185.23625]\n",
      " [153.24281]\n",
      " [148.3488 ]\n",
      " [192.77802]\n",
      " [148.82515]\n",
      " [172.19609]\n",
      " [174.28006]\n",
      " [154.62086]\n",
      " [172.24364]\n",
      " [178.59798]\n",
      " [162.71518]\n",
      " [145.69466]\n",
      " [194.39421]]\n",
      "\n",
      "Step : 1000 \n",
      "Cost : 32.8203010559082 \n",
      "Prediction :\n",
      "[[146.8997  ]\n",
      " [190.00137 ]\n",
      " [180.22098 ]\n",
      " [197.4235  ]\n",
      " [147.23227 ]\n",
      " [111.756676]\n",
      " [145.60976 ]\n",
      " [104.548386]\n",
      " [182.0209  ]\n",
      " [172.24463 ]\n",
      " [143.11383 ]\n",
      " [147.44116 ]\n",
      " [185.30093 ]\n",
      " [153.29468 ]\n",
      " [148.40265 ]\n",
      " [192.64053 ]\n",
      " [148.77307 ]\n",
      " [172.41382 ]\n",
      " [174.40532 ]\n",
      " [154.77252 ]\n",
      " [172.32716 ]\n",
      " [178.46078 ]\n",
      " [162.83325 ]\n",
      " [145.92358 ]\n",
      " [194.30359 ]]\n",
      "\n",
      "Step : 1100 \n",
      "Cost : 31.310731887817383 \n",
      "Prediction :\n",
      "[[147.09245]\n",
      " [189.85094]\n",
      " [180.271  ]\n",
      " [197.4618 ]\n",
      " [147.03587]\n",
      " [111.54234]\n",
      " [145.7217 ]\n",
      " [104.75907]\n",
      " [181.77196]\n",
      " [171.94423]\n",
      " [143.12431]\n",
      " [147.27672]\n",
      " [185.36208]\n",
      " [153.34254]\n",
      " [148.45625]\n",
      " [192.50789]\n",
      " [148.71953]\n",
      " [172.6266 ]\n",
      " [174.52502]\n",
      " [154.91809]\n",
      " [172.40932]\n",
      " [178.32849]\n",
      " [162.94853]\n",
      " [146.14268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [194.21509]]\n",
      "\n",
      "Step : 1200 \n",
      "Cost : 29.892072677612305 \n",
      "Prediction :\n",
      "[[147.27853]\n",
      " [189.70496]\n",
      " [180.31886]\n",
      " [197.49908]\n",
      " [146.84492]\n",
      " [111.33551]\n",
      " [145.83133]\n",
      " [104.9655 ]\n",
      " [181.53171]\n",
      " [171.6559 ]\n",
      " [143.13495]\n",
      " [147.11844]\n",
      " [185.41992]\n",
      " [153.3866 ]\n",
      " [148.50952]\n",
      " [192.37988]\n",
      " [148.66464]\n",
      " [172.83456]\n",
      " [174.63943]\n",
      " [155.0578 ]\n",
      " [172.49008]\n",
      " [178.20087]\n",
      " [163.06107]\n",
      " [146.35239]\n",
      " [194.12863]]\n",
      "\n",
      "Step : 1300 \n",
      "Cost : 28.558568954467773 \n",
      "Prediction :\n",
      "[[147.45818]\n",
      " [189.56334]\n",
      " [180.3647 ]\n",
      " [197.53542]\n",
      " [146.65926]\n",
      " [111.13591]\n",
      " [145.93867]\n",
      " [105.16774]\n",
      " [181.29985]\n",
      " [171.37917]\n",
      " [143.14574]\n",
      " [146.9661 ]\n",
      " [185.4746 ]\n",
      " [153.42705]\n",
      " [148.56248]\n",
      " [192.25636]\n",
      " [148.6086 ]\n",
      " [173.03777]\n",
      " [174.74876]\n",
      " [155.19188]\n",
      " [172.56947]\n",
      " [178.07777]\n",
      " [163.17091]\n",
      " [146.55305]\n",
      " [194.04422]]\n",
      "\n",
      "Step : 1400 \n",
      "Cost : 27.304662704467773 \n",
      "Prediction :\n",
      "[[147.63162 ]\n",
      " [189.42595 ]\n",
      " [180.40857 ]\n",
      " [197.57077 ]\n",
      " [146.47873 ]\n",
      " [110.943275]\n",
      " [146.0438  ]\n",
      " [105.36585 ]\n",
      " [181.07605 ]\n",
      " [171.11354 ]\n",
      " [143.15662 ]\n",
      " [146.81946 ]\n",
      " [185.52628 ]\n",
      " [153.46413 ]\n",
      " [148.61505 ]\n",
      " [192.13715 ]\n",
      " [148.5515  ]\n",
      " [173.23634 ]\n",
      " [174.85324 ]\n",
      " [155.32056 ]\n",
      " [172.6475  ]\n",
      " [177.95901 ]\n",
      " [163.27812 ]\n",
      " [146.74509 ]\n",
      " [193.96179 ]]\n",
      "\n",
      "Step : 1500 \n",
      "Cost : 26.125165939331055 \n",
      "Prediction :\n",
      "[[147.79912 ]\n",
      " [189.29262 ]\n",
      " [180.45058 ]\n",
      " [197.60521 ]\n",
      " [146.30318 ]\n",
      " [110.757324]\n",
      " [146.14674 ]\n",
      " [105.559906]\n",
      " [180.86003 ]\n",
      " [170.8586  ]\n",
      " [143.1676  ]\n",
      " [146.6783  ]\n",
      " [185.57507 ]\n",
      " [153.49802 ]\n",
      " [148.66722 ]\n",
      " [192.02208 ]\n",
      " [148.4935  ]\n",
      " [173.43039 ]\n",
      " [174.95308 ]\n",
      " [155.4441  ]\n",
      " [172.72418 ]\n",
      " [177.84444 ]\n",
      " [163.3828  ]\n",
      " [146.92891 ]\n",
      " [193.8813  ]]\n",
      "\n",
      "Step : 1600 \n",
      "Cost : 25.015398025512695 \n",
      "Prediction :\n",
      "[[147.96088]\n",
      " [189.16324]\n",
      " [180.4908 ]\n",
      " [197.63876]\n",
      " [146.13248]\n",
      " [110.57783]\n",
      " [146.2475 ]\n",
      " [105.74997]\n",
      " [180.65149]\n",
      " [170.61383]\n",
      " [143.17867]\n",
      " [146.5424 ]\n",
      " [185.62115]\n",
      " [153.52887]\n",
      " [148.71896]\n",
      " [191.91101]\n",
      " [148.43472]\n",
      " [173.62   ]\n",
      " [175.0485 ]\n",
      " [155.56268]\n",
      " [172.79951]\n",
      " [177.7339 ]\n",
      " [163.48495]\n",
      " [147.1048 ]\n",
      " [193.80272]]\n",
      "\n",
      "Step : 1700 \n",
      "Cost : 23.970928192138672 \n",
      "Prediction :\n",
      "[[148.11708]\n",
      " [189.03767]\n",
      " [180.52931]\n",
      " [197.67143]\n",
      " [145.96645]\n",
      " [110.40455]\n",
      " [146.34615]\n",
      " [105.93608]\n",
      " [180.45015]\n",
      " [170.37888]\n",
      " [143.18977]\n",
      " [146.41154]\n",
      " [185.66466]\n",
      " [153.55685]\n",
      " [148.77022]\n",
      " [191.8038 ]\n",
      " [148.37526]\n",
      " [173.80522]\n",
      " [175.13966]\n",
      " [155.67651]\n",
      " [172.8735 ]\n",
      " [177.62721]\n",
      " [163.58466]\n",
      " [147.27315]\n",
      " [193.72597]]\n",
      "\n",
      "Step : 1800 \n",
      "Cost : 22.987531661987305 \n",
      "Prediction :\n",
      "[[148.26799 ]\n",
      " [188.9158  ]\n",
      " [180.56618 ]\n",
      " [197.70326 ]\n",
      " [145.805   ]\n",
      " [110.237236]\n",
      " [146.44272 ]\n",
      " [106.11835 ]\n",
      " [180.25574 ]\n",
      " [170.1533  ]\n",
      " [143.20094 ]\n",
      " [146.28557 ]\n",
      " [185.70569 ]\n",
      " [153.58215 ]\n",
      " [148.82101 ]\n",
      " [191.70029 ]\n",
      " [148.31525 ]\n",
      " [173.98622 ]\n",
      " [175.2268  ]\n",
      " [155.78581 ]\n",
      " [172.94617 ]\n",
      " [177.52426 ]\n",
      " [163.68199 ]\n",
      " [147.43427 ]\n",
      " [193.65103 ]]\n",
      "\n",
      "Step : 1900 \n",
      "Cost : 22.06146240234375 \n",
      "Prediction :\n",
      "[[148.41376 ]\n",
      " [188.7975  ]\n",
      " [180.60147 ]\n",
      " [197.73424 ]\n",
      " [145.64798 ]\n",
      " [110.075676]\n",
      " [146.53723 ]\n",
      " [106.29678 ]\n",
      " [180.068   ]\n",
      " [169.93672 ]\n",
      " [143.21213 ]\n",
      " [146.16425 ]\n",
      " [185.74438 ]\n",
      " [153.60492 ]\n",
      " [148.8713  ]\n",
      " [191.60034 ]\n",
      " [148.25476 ]\n",
      " [174.16304 ]\n",
      " [175.31006 ]\n",
      " [155.89072 ]\n",
      " [173.01752 ]\n",
      " [177.42491 ]\n",
      " [163.77698 ]\n",
      " [147.58847 ]\n",
      " [193.57788 ]]\n",
      "\n",
      "Step : 2000 \n",
      "Cost : 21.18906021118164 \n",
      "Prediction :\n",
      "[[148.55458 ]\n",
      " [188.68266 ]\n",
      " [180.63527 ]\n",
      " [197.76442 ]\n",
      " [145.49522 ]\n",
      " [109.919655]\n",
      " [146.62971 ]\n",
      " [106.47149 ]\n",
      " [179.8867  ]\n",
      " [169.72878 ]\n",
      " [143.22334 ]\n",
      " [146.0474  ]\n",
      " [185.78082 ]\n",
      " [153.62527 ]\n",
      " [148.92107 ]\n",
      " [191.5038  ]\n",
      " [148.19392 ]\n",
      " [174.33578 ]\n",
      " [175.3896  ]\n",
      " [155.99147 ]\n",
      " [173.08754 ]\n",
      " [177.32901 ]\n",
      " [163.8697  ]\n",
      " [147.73605 ]\n",
      " [193.50642 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in range(2001) : \n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "    [cost, hypothesis, train], feed_dict = {X : x_data, Y : y_data})\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fd69e6dc83425a9a516dc877dbeec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2001), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step : 0 \tCost : 30871.0390625 \n",
      "Step : 1 \tCost : 11448.2578125 \n",
      "Step : 2 \tCost : 4267.099609375 \n",
      "Step : 3 \tCost : 1612.0084228515625 \n",
      "Step : 4 \tCost : 630.3294677734375 \n",
      "Step : 5 \tCost : 267.35614013671875 \n",
      "Step : 6 \tCost : 133.13693237304688 \n",
      "Step : 7 \tCost : 83.49371337890625 \n",
      "Step : 8 \tCost : 65.12068939208984 \n",
      "Step : 9 \tCost : 58.30916976928711 \n",
      "Step : 100 \tCost : 51.731849670410156 \n",
      "Step : 200 \tCost : 49.04936981201172 \n",
      "Step : 300 \tCost : 46.53648376464844 \n",
      "Step : 400 \tCost : 44.1815299987793 \n",
      "Step : 500 \tCost : 41.97384262084961 \n",
      "Step : 600 \tCost : 39.903438568115234 \n",
      "Step : 700 \tCost : 37.961181640625 \n",
      "Step : 800 \tCost : 36.13839340209961 \n",
      "Step : 900 \tCost : 34.42721939086914 \n",
      "Step : 1000 \tCost : 32.8203010559082 \n",
      "Step : 1100 \tCost : 31.310731887817383 \n",
      "Step : 1200 \tCost : 29.892072677612305 \n",
      "Step : 1300 \tCost : 28.558568954467773 \n",
      "Step : 1400 \tCost : 27.304662704467773 \n",
      "Step : 1500 \tCost : 26.125165939331055 \n",
      "Step : 1600 \tCost : 25.015398025512695 \n",
      "Step : 1700 \tCost : 23.970928192138672 \n",
      "Step : 1800 \tCost : 22.987531661987305 \n",
      "Step : 1900 \tCost : 22.06146240234375 \n",
      "Step : 2000 \tCost : 21.18906021118164 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for step in tqdm_notebook(range(2001)) :\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict = {X : x_data, Y : y_data})\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        # print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "        print(\"Step : {} \\tCost : {} \".format(step, cost_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your score \t: \n",
      " [[207.16539]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Your score \\t: \\n\", sess.run(hypothesis, feed_dict={X: [[100, 70, 101]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Other scores \t: \n",
      " [[169.10136]\n",
      " [170.76434]]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOther scores \\t: \\n\", sess.run(hypothesis,\n",
    "                                        feed_dict={X: [[60, 70, 110], [90, 100, 80]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ex04. TF reader linear regression 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0911 11:14:16.658407  5588 deprecation.py:323] From <ipython-input-1-3a86c153738d>:6: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0911 11:14:16.672038  5588 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "W0911 11:14:16.673033  5588 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "W0911 11:14:16.676922  5588 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0911 11:14:16.679851  5588 deprecation.py:323] From C:\\Python\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\training\\input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0911 11:14:16.685712  5588 deprecation.py:323] From <ipython-input-1-3a86c153738d>:8: TextLineReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\n",
      "W0911 11:14:16.692548  5588 deprecation.py:323] From <ipython-input-1-3a86c153738d>:15: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "filename_queue = tf.train.string_input_producer(\n",
    "['./data/data-01-test-scort.csv'], shuffle = False, name = 'filename_queue')\n",
    "\n",
    "reader = tf.TextLineReader()\n",
    "key, value = reader.read(filename_queue)\n",
    "\n",
    "record_defaults = [[0.],[0.],[0.],[0.]]\n",
    "xy = tf.decode_csv(value, record_defaults = record_defaults)\n",
    "\n",
    "train_x_batch, train_y_batch = \\\n",
    "    tf.train.batch([xy[0:-1], xy[-1:]], batch_size=10)\n",
    "\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None,3])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "W = tf.Variable(tf.random_normal([3,1]), name = 'weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "hypothesis = tf.matmul(X, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = 1e-5)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0911 11:14:20.996477  5588 deprecation.py:323] From <ipython-input-3-888db051c089>:6: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "coord = tf.train.Coordinator()\n",
    "threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "\n",
    "Step_val = []\n",
    "Cost_val = []\n",
    "\n",
    "for step in tqdm_notebook(range(2001)):\n",
    "\n",
    "    x_batch, y_batch = sess.run([train_x_batch, train_y_batch])\n",
    "    cost_val, hy_val, _ = sess.run(\n",
    "        [cost, hypothesis, train], feed_dict={X: x_batch, Y: y_batch})\n",
    "\n",
    "    Step_val.append(step)\n",
    "    Cost_val.append(cost_val)\n",
    "    \n",
    "    if step % 100 == 0 or step < 10 :\n",
    "        print(\"\\nStep : {} \\nCost : {} \\nPrediction :\\n{}\".format(step, cost_val, hy_val))\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
